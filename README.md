# 🤖 Machine Learning Assignments – ANU, Spring 2025

Welcome to my collection of 📚 **Machine Learning Assignments** developed as part of my coursework at Alexandria National University.  
These projects demonstrate core ML concepts through practical implementation of algorithms like **Linear Regression**, **Logistic Regression**, **KNN**, **SVM**, and **Neural Networks**, all using real-world datasets and Python tools. 🐍💡

---

## 📂 Assignments Overview

### 🧮 Assignment 1: Regression & Logistic Regression

🔍 **Objective:** Explore regression and binary classification using real-world datasets.  
📊 **Topics Covered:**
- 🔹 **Simple & Multiple Linear Regression**
- 🔹 **Polynomial Regression** (degree 2–4)
- 🔹 **Logistic Regression**

🛠️ **What I Did:**
- Performed full EDA (heatmaps, scatter plots, etc.)
- Cleaned and preprocessed data (missing values, encoding, scaling)
- Visualized regression lines and compared performance using R² and MSE
- Evaluated classification with confusion matrix and accuracy scores

📌 **Tools:** `pandas`, `matplotlib`, `seaborn`, `scikit-learn`

---

### 👣 Assignment 2: K-Nearest Neighbors (KNN) & Evaluation Techniques

🎯 **Objective:** Implement KNN and evaluate model performance with different techniques  
📊 **Tasks Completed:**
- Split data into **Training (60%)**, **Validation (20%)**, **Test (20%)**
- Tuned the `K` value for optimal accuracy
- Applied **k-Fold Cross-Validation** (5 or 10 folds)
- Compared:
  - Validation vs Cross-Validation vs Test results
  - Confusion matrix + metrics: **Accuracy**, **Precision**, **Recall**, **F1-score**
- Discussed overfitting and strategies to improve model performance

📈 **Visuals:** Heatmaps, accuracy plots, 2D visualizations (optional)

📌 **Tools:** `scikit-learn`, `matplotlib`, `seaborn`

---

### 🧠 Assignment 3: SVM vs Neural Networks for Classification

🚀 **Objective:** Compare performance of **Support Vector Machines (SVM)** and **Neural Networks** on a classification task  
📊 **Dataset Options:** Iris 🌸, MNIST ✍️, Wine 🍷, Breast Cancer 🧬

🧪 **Tasks Performed:**
- EDA + preprocessing (normalization, encoding, data cleaning)
- ✅ **SVM**:
  - Tried different kernels: **Linear**, **Polynomial**, **RBF**
  - Evaluated performance via confusion matrix and accuracy
- 🔁 **Neural Network**:
  - Implemented a basic **Feedforward Neural Network** (Keras/PyTorch)
  - Used **ReLU**, **Sigmoid** activations
  - Tracked **loss curve**, accuracy, and confusion matrix

📊 **Comparison**:
- Used metrics: **Accuracy**, **Precision**, **Recall**, **F1-score**
- Plotted **ROC Curves**
- Analyzed overfitting/underfitting and suggested improvements

📌 **Tools:** `Keras`, `scikit-learn`, `matplotlib`, `seaborn`

---

